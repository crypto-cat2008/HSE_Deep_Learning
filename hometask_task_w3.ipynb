{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"dqpq0qGHyfBD","executionInfo":{"status":"ok","timestamp":1666631554898,"user_tz":240,"elapsed":546,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EurL1__QiWWP"},"source":["<div class=\"alert alert-warning\">\n","\n","### Load this Jupyter Notebook into Google Colab for better performance! (use GPU environment)\n","\n","https://colab.research.google.com/\n","\n","\n","**Coursera Labs does not provide enough CPU and memory.**\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"MZ683WYungkb"},"source":["![title](img.jpg)\n","![title](img2.jpg)"]},{"cell_type":"markdown","metadata":{"id":"HdsPA6SnyfBP"},"source":["torchvision model tuning\n","------------------------------\n","\n","In this task you will have to run all the steps of the lab and save final model weights into `final_model.pt` file, which you will have to submit as the result of your work into Coursera Lab environment by clicking Submit Assignment button.\n","\n","Part of the steps are complete, others will require you to do simple excercises.\n"]},{"cell_type":"markdown","metadata":{"id":"EQo04hGeyfBR"},"source":["https://pytorch.org/docs/stable/torchvision/models.html - models trained on ImageNet\n","\n","First we get the pre-trained model and then use feature extraction for final layers training.\n","\n","Steps:\n","-  get data\n","-  init pre-trained model\n","-  add new head layer, change output shape for desired dataset\n","-  define how we train our model (update only final layers or all)\n","-  train\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"2_golg5tyfBS","executionInfo":{"status":"ok","timestamp":1666633669709,"user_tz":240,"elapsed":270,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[],"source":["from __future__ import print_function, division\n","\n","import time\n","import os\n","import copy\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torchvision\n","from torchvision import datasets, models, transforms\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"jvCirGXNyfBb"},"source":["Data\n","------\n","\n","We will use *hymenoptera_data*: https://download.pytorch.org/tutorial/hymenoptera_data.zip.\n","It has 2 classes - bees and ants.\n","To get data we will use class ImageFolder - https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.ImageFolder\n","\n","As a model we take vgg11_bn - VGG11 trained with batch normalization\n","\n","Other params:\n","batch_size - size of the batch, num_classes - amount of different classes in data, num_epochs - how many epochs to train for, finetune - flag to determine if we train only last layers or the whole model\n","\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"OEH1_3YYgGjE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"58f53d80-1096-4b27-ab85-a72b00723348","executionInfo":{"status":"ok","timestamp":1666633696740,"user_tz":240,"elapsed":24610,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-24 17:47:52--  https://download.pytorch.org/tutorial/hymenoptera_data.zip\n","Resolving download.pytorch.org (download.pytorch.org)... 13.227.219.43, 13.227.219.108, 13.227.219.81, ...\n","Connecting to download.pytorch.org (download.pytorch.org)|13.227.219.43|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 47286322 (45M) [application/zip]\n","Saving to: ‘hymenoptera_data.zip.2’\n","\n","hymenoptera_data.zi 100%[===================>]  45.10M  54.3MB/s    in 0.8s    \n","\n","2022-10-24 17:47:53 (54.3 MB/s) - ‘hymenoptera_data.zip.2’ saved [47286322/47286322]\n","\n","mkdir: cannot create directory ‘data’: File exists\n","Archive:  hymenoptera_data.zip\n","replace hymenoptera_data/train/ants/0013035.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace hymenoptera_data/train/ants/1030023514_aad5c608f9.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}],"source":["! wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n","! mkdir data\n","! unzip hymenoptera_data.zip"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"ehENWHPBgWck","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2db1e56d-469c-4ec4-c2ac-e37d7eb54b7f","executionInfo":{"status":"ok","timestamp":1666633700444,"user_tz":240,"elapsed":474,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["mv: cannot move 'hymenoptera_data' to 'data/hymenoptera_data': Directory not empty\n","hymenoptera_data\n"]}],"source":["! mv hymenoptera_data data/\n","! ls ./data"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"LE8OgQadyfBj","executionInfo":{"status":"ok","timestamp":1666633702479,"user_tz":240,"elapsed":218,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[],"source":["data_dir = \"./data/hymenoptera_data\" # path to data\n","num_classes = 2                      # amount of classes in new data\n","\n","batch_size = 8                       # data batch size\n","num_epochs = 5                       # epochs count\n","feature_extract = True               # should we train with feature extraction (last layers fine tuning)"]},{"cell_type":"markdown","metadata":{"id":"h578K9e1kwsQ"},"source":["Model training\n","---------------\n","\n","And helper for layers params setup"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"reg1vQMdyfB4","executionInfo":{"status":"ok","timestamp":1666633704402,"user_tz":240,"elapsed":211,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n","    start = time.time()\n","    _hist = []\n","    best_model = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","\n","        for phase in ['train', 'val']:\n","            model.train() if phase == 'train' else model.eval()\n","            _loss, _acc = 0.0, 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                _loss += loss.item() * inputs.size(0)\n","                _acc += torch.sum(preds == labels.data)\n","\n","            epoch_loss = _loss / len(dataloaders[phase].dataset)\n","            epoch_acc = _acc.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.6f} Acc: {:.6f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            if phase == 'val':\n","                _hist.append(epoch_acc)\n","                if epoch_acc > best_acc:\n","                  best_acc = epoch_acc\n","                  best_model = copy.deepcopy(model.state_dict())\n","\n","    time_elapsed = time.time() - start\n","    print('Training finished: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Validation: best score Accuracy: {:6f}'.format(best_acc))\n","\n","    model.load_state_dict(best_model)\n","    return model, _hist\n","\n","\n","def set_requires_grad(model, feature_extract):\n","    if feature_extract:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"8t_IfO5UyfEa"},"source":["Model init and update\n","-----------------------------------\n","\n","For more details - https://pytorch.org/docs/stable/torchvision/models.html\n","\n","In this block we change model's final layer. It is hard to automate this step, as each model has its own characteristics. Last layer of CNN model (usually fully conntected) has the same amount of outputs as the dataset classes. All models in torchvision are trained on Imagenet, so the size of the final layer is 1000.\n","\n","Our goal - get the final layer to have the same inputs amount and change amount of outputs to satisfy the requirements of new dataset.\n","\n","Important notice to distinguish retraining and feature extraction (final layers training, finetuning): in the last case we want to update only final layer (layers), meaning we ignore gradients calculation for the previous layers, in order to do so we set `required_grad=False` parameter of the layers. By default, the parameter is `True` (including newly created layer, but we do want to update it, that is why we do not set that param for the new layer).\n","\n","VGG\n","---\n","\n","More details about the model - https://arxiv.org/pdf/1409.1556.pdf\n","\n","In torchvision library there is 8 versions of pre-trained VGG model with different size and batch-normalization usage. We will use VGG-11 with batch-normalization.\n","\n","In model description we can see: classifier (model's head) includes final layer - Linear with 4096 input params and 1000 outputs:.\n","```\n","   (classifier): Sequential(\n","       ...\n","       (6): Linear(in_features=4096, out_features=1000, bias=True)\n","    )\n","```\n","We can change it by using following code:\n","\n","`model.classifier[6] = nn.Linear(4096,num_classes)`\n","\n","We update sixth (last) layer in classifier block of model's layers sequence."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"wCLS9IwryfEa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5f96be85-78df-4098-d029-e523ad776894","executionInfo":{"status":"ok","timestamp":1666633709463,"user_tz":240,"elapsed":1475,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace=True)\n","    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (13): ReLU(inplace=True)\n","    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (17): ReLU(inplace=True)\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (20): ReLU(inplace=True)\n","    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (24): ReLU(inplace=True)\n","    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (27): ReLU(inplace=True)\n","    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=2, bias=True)\n","  )\n",")\n"]}],"source":["def initialize_model(num_classes, feature_extract, use_pretrained=True):\n","    model_ft = models.vgg11_bn(pretrained=use_pretrained)\n","    \n","    set_requires_grad(model_ft, feature_extract)\n","\n","    num_ftrs = model_ft.classifier[6].in_features\n","\n","    #\n","    #\n","    # PUT CODE TO REPLACE LAYER HERE\n","    #\n","    #\n","    model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n","\n","    input_size = 224\n","    \n","    return model_ft, input_size\n","\n","model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n","print(model_ft)"]},{"cell_type":"markdown","metadata":{"id":"BAqawD0tyfEe"},"source":["Data loader\n","---------\n","\n","Now knowing input data params we can init data loader.\n","Important notice: models are trained with normalization values, details - https://pytorch.org/docs/master/torchvision/models.html\n","\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Z4L9ykOoyfEl","executionInfo":{"status":"ok","timestamp":1666633714390,"user_tz":240,"elapsed":191,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[],"source":["# Data normalization\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","image_datasets = {\n","    x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                            data_transforms[x])\n","    for x in ['train', 'val']\n","}\n","dataloaders_dict = {\n","    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n","                                   shuffle=True, num_workers=4)\n","    for x in ['train', 'val']\n","}\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"jIoLgvHTyfEu"},"source":["Init optimizer\n","--------------------\n","\n","Now we have model and data, last thing left is to create optimizer, which will update only required params. We already specified `required_grad` param before.\n","\n","We have to pass those (and only those) params into SGD for optimization\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"tgc222EXyfEu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6033ec16-43ff-4324-b0bb-29b09fd97ea7","executionInfo":{"status":"ok","timestamp":1666633716784,"user_tz":240,"elapsed":253,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Params to update while training:\n","\t classifier.6.weight\n","\t classifier.6.bias\n"]}],"source":["model_ft = model_ft.to(device)\n","\n","params_to_update = model_ft.parameters() # all params by default\n","print(\"Params to update while training:\")\n","\n","if feature_extract:\n","    # only last layer, update the list\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    # all params, just output\n","    for name, param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","optimizer_ft = optim.SGD(params_to_update, lr=0.002, momentum=0.9)"]},{"cell_type":"markdown","metadata":{"id":"6QiVtDcRyfEz"},"source":["Training and validation\n","--------------------------------\n","\n","Now we have to determine loss function and start training process for specified amount of epochs. CPU learning might require some time (depending on the model), and learning rate could be optimized as well (as it is not optimal by default).\n","\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"a17i9JUxyfE0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"52ecc075-685a-4839-b5f3-8ffd9b4a8e39","executionInfo":{"status":"ok","timestamp":1666633850998,"user_tz":240,"elapsed":132017,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/24\n","train Loss: 0.423864 Acc: 0.786885\n","val Loss: 0.183229 Acc: 0.915033\n","Epoch 1/24\n","train Loss: 0.253301 Acc: 0.893443\n","val Loss: 0.144838 Acc: 0.928105\n","Epoch 2/24\n","train Loss: 0.217577 Acc: 0.930328\n","val Loss: 0.155220 Acc: 0.941176\n","Epoch 3/24\n","train Loss: 0.185524 Acc: 0.905738\n","val Loss: 0.128910 Acc: 0.928105\n","Epoch 4/24\n","train Loss: 0.297631 Acc: 0.885246\n","val Loss: 0.132889 Acc: 0.934641\n","Epoch 5/24\n","train Loss: 0.196933 Acc: 0.913934\n","val Loss: 0.171034 Acc: 0.934641\n","Epoch 6/24\n","train Loss: 0.273108 Acc: 0.889344\n","val Loss: 0.139762 Acc: 0.928105\n","Epoch 7/24\n","train Loss: 0.265384 Acc: 0.893443\n","val Loss: 0.163295 Acc: 0.934641\n","Epoch 8/24\n","train Loss: 0.223720 Acc: 0.913934\n","val Loss: 0.198858 Acc: 0.921569\n","Epoch 9/24\n","train Loss: 0.172989 Acc: 0.913934\n","val Loss: 0.225770 Acc: 0.928105\n","Epoch 10/24\n","train Loss: 0.201707 Acc: 0.926230\n","val Loss: 0.188254 Acc: 0.934641\n","Epoch 11/24\n","train Loss: 0.240828 Acc: 0.901639\n","val Loss: 0.160700 Acc: 0.921569\n","Epoch 12/24\n","train Loss: 0.187653 Acc: 0.938525\n","val Loss: 0.183654 Acc: 0.915033\n","Epoch 13/24\n","train Loss: 0.239105 Acc: 0.913934\n","val Loss: 0.177749 Acc: 0.928105\n","Epoch 14/24\n","train Loss: 0.243127 Acc: 0.909836\n","val Loss: 0.213495 Acc: 0.941176\n","Epoch 15/24\n","train Loss: 0.225767 Acc: 0.913934\n","val Loss: 0.246347 Acc: 0.934641\n","Epoch 16/24\n","train Loss: 0.280195 Acc: 0.901639\n","val Loss: 0.198347 Acc: 0.947712\n","Epoch 17/24\n","train Loss: 0.289326 Acc: 0.897541\n","val Loss: 0.199504 Acc: 0.941176\n","Epoch 18/24\n","train Loss: 0.292407 Acc: 0.868852\n","val Loss: 0.180890 Acc: 0.928105\n","Epoch 19/24\n","train Loss: 0.322512 Acc: 0.905738\n","val Loss: 0.171260 Acc: 0.941176\n","Epoch 20/24\n","train Loss: 0.316104 Acc: 0.889344\n","val Loss: 0.179257 Acc: 0.934641\n","Epoch 21/24\n","train Loss: 0.226159 Acc: 0.913934\n","val Loss: 0.172313 Acc: 0.947712\n","Epoch 22/24\n","train Loss: 0.219477 Acc: 0.909836\n","val Loss: 0.192687 Acc: 0.941176\n","Epoch 23/24\n","train Loss: 0.277346 Acc: 0.909836\n","val Loss: 0.195671 Acc: 0.941176\n","Epoch 24/24\n","train Loss: 0.222139 Acc: 0.918033\n","val Loss: 0.205445 Acc: 0.928105\n","Training finished: 2m 12s\n","Validation: best score Accuracy: 0.947712\n"]}],"source":["# loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# training\n","# TODO: call train_model will all required params:\n","# model_ft, hist = None, None # train_model(...)\n","model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=25)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QjEC9hoHRhg","executionInfo":{"status":"ok","timestamp":1666633877241,"user_tz":240,"elapsed":19378,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}},"outputId":"4d34bd26-2e70-4694-dfb0-ae3b12efaf28"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"6HOVWVsHUhn8"},"source":["Save resulting model weights"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"dyx18Pu8Uje8","executionInfo":{"status":"ok","timestamp":1666633915090,"user_tz":240,"elapsed":2284,"user":{"displayName":"Susan Malkin","userId":"07747390338629969515"}}},"outputs":[],"source":["torch.save(model_ft.state_dict(), '/content/drive/MyDrive/final_model.pt')"]},{"cell_type":"markdown","metadata":{"id":"Q0ibZjstiIyn"},"source":["Saved file can be found in directory menu on the left in Google Colab interface."]},{"cell_type":"markdown","metadata":{"id":"-lBaxtEWngku"},"source":["<div class=\"alert alert-warning\">\n","\n","Save `final_model.pt` file from Google Colab to your computer and than upload it to the Coursera Lab environment. When finish downloading, click \"Submit Assignment\" in this notebook.\n","\n","![image.png](attachment:image.png)\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OAAo332ngkv"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yqIDJ6mtngkv"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"coursera":{"schema_names":["pytorch-jupyter-task-83acec"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"5f4626d50a060da4b47e18776c852ab1c193f00f2162881a84608752df882344"}}},"nbformat":4,"nbformat_minor":0}